{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup Environment\n",
    "#!pip install --quiet tensorflow==1.15.0\n",
    "#!pip install --quiet tensorflow_hub==0.5.0\n",
    "#!pip install --quiet tf_sentencepiece==0.1.86\n",
    "#!pip install --quiet googletrans==2.4.0\n",
    "#!pip install --quiet japanize-matplotlib==1.0.4\n",
    "#!pip install --quiet mecab-python3\n",
    "#!pip install --quiet https://github.com/megagonlabs/ginza/releases/download/v1.0.2/ja_ginza_nopn-1.0.2.tgz\n",
    "#!pip install --quiet https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz\n",
    "    \n",
    "#!ln -s /usr/local/lib/python3.6/dist-packages/ja_ginza_nopn /usr/local/lib/python3.6/dist-packages/spacy/data/ja_ginza_nopn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup common imports and functions\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tensorflow_hub as hub\n",
    "import tf_sentencepiece\n",
    "from googletrans import Translator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import japanize_matplotlib\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "from IPython.display import HTML\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def ncossim(embs_1, embs_2, axis=0):\n",
    "    sims = np.inner(embs_1, embs_2)\n",
    "    std = np.std(sims, axis=axis)\n",
    "    ex = np.mean((sims-np.min(sims, axis=axis))/np.max(sims, axis=axis), axis=axis)\n",
    "    return 0.5 + (sims-ex)/std\n",
    "\n",
    "\n",
    "def mmr(doc_emb, cand_embs, key_embs):\n",
    "    param = 0.5\n",
    "    scores = param * ncossim(cand_embs, doc_emb, axis=0)\n",
    "    if key_embs is not None:\n",
    "        scores -= (1-param) * np.max(ncossim(cand_embs, key_embs), axis=1).reshape(scores.shape[0], -1)\n",
    "    return scores\n",
    "\n",
    "'''\n",
    "def embedrank(doc_emb, sent_embs, n_keys):\n",
    "    assert 0 < n_keys, 'Please `key_size` value set more than 0'\n",
    "    assert n_keys < len(sent_embs), 'Please `key_size` value set lower than `#sentences`'\n",
    "    sims = np.inner(doc_emb, sent_embs).reshape(-1)\n",
    "    return np.argsort(-sims)[:n_keys]\n",
    "'''\n",
    "\n",
    "def embedrankpp(doc_emb, sent_embs, n_keys):\n",
    "    assert 0 < n_keys, 'Please `key_size` value set more than 0'\n",
    "    assert n_keys < len(sent_embs), 'Please `key_size` value set lower than `#sentences`'\n",
    "    cand_idx = list(range(len(sent_embs)))\n",
    "    key_idx = []\n",
    "    while len(key_idx) < n_keys:\n",
    "        cand_embs = sent_embs[cand_idx]\n",
    "        key_embs = sent_embs[key_idx] if len(key_idx) > 0 else None\n",
    "        scores = mmr(doc_emb, cand_embs, key_embs)\n",
    "        key_idx.append(cand_idx[np.argmax(scores)])\n",
    "        cand_idx.pop(np.argmax(scores))\n",
    "    return key_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "#@title Build a model\n",
    "encoder = 'universal-sentence-encoder-multilingual'\n",
    "module_url = 'https://tfhub.dev/google/universal-sentence-encoder-multilingual/1'\n",
    "\n",
    "\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    text_input = tf.placeholder(dtype=tf.string, shape=[None])\n",
    "    xling_embed = hub.Module(module_url)\n",
    "    embedded_text = xling_embed(text_input)\n",
    "    init_options = tf.group([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "g.finalize()\n",
    "\n",
    "session = tf.Session(graph=g)\n",
    "session.run(init_options)\n",
    "\n",
    "    \n",
    "ranker = 'EmbedRank++' \n",
    "rank_fn = embedrankpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document from Wikipedia\n",
    "'''\n",
    "doc = [\"\"\"\n",
    "I dropped out of Reed College after the first 6 months, but then stayed around as a drop-in for another 18 months or so before I really quit.\n",
    "It was the first computer with beautiful typography.\n",
    "I had been rejected, but I was still in love.\n",
    "Your work is going to fill a large part of your life, and the only way to be truly satisfied is to do what you believe is great work.\n",
    "I didn’t even know what a pancreas was.\n",
    "When I was young, there was an amazing publication called The Whole Earth Catalog, which was one of the bibles of my generation.\n",
    "The major limitation is that standard language models are unidirectional, and this limits the choice of architectures that can be used during pre-training.\n",
    "\"\"\"]'''\n",
    "\n",
    "from src.main import long_summary\n",
    "\n",
    "doc = []\n",
    "doc.append(long_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: en\n",
      "#sentences: 8\n"
     ]
    }
   ],
   "source": [
    "#@title Language detection and sentence segmentation\n",
    "translator = Translator()\n",
    "detected_lang = translator.detect(''.join(doc))\n",
    "\n",
    "assert detected_lang.lang in ['en'], 'Please, input Japanese text or English text'\n",
    "detected_lang.lang = 'en':\n",
    "tokenizer = spacy.load('en_core_web_sm')\n",
    "\n",
    "sents = [str(s).replace('\\n', '') for s in tokenizer(''.join(doc)).sents]\n",
    "#print(f'Language: {detected_lang.lang}')\n",
    "#print(f'#sentences: {len(sents)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Model run\n",
    "key_size = 3 #@param {type:\"integer\"}\n",
    "\n",
    "# Embedding\n",
    "doc_emb= session.run(embedded_text, feed_dict={text_input: doc})\n",
    "sent_embs= session.run(embedded_text, feed_dict={text_input: sents})\n",
    "\n",
    "# Ranking\n",
    "keys = rank_fn(doc_emb, sent_embs, key_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<font color=\"#CD5C5C\"><strong>I dropped out of Reed College after the first 6 months, but then stayed around as a drop-in for another 18 months or so before I really quit.</strong></font><font color=\"#CD5C5C\"><strong>It was the first computer with beautiful typography.</strong></font>I had been rejected, but I was still in love.Your work is going to fill a large part of your life, and the only way to be truly satisfied is to do what you believe is great work.I didn’teven know what a pancreas was.<font color=\"#CD5C5C\"><strong>When I was young, there was an amazing publication called The Whole Earth Catalog, which was one of the bibles of my generation.</strong></font>The major limitation is that standard language models are unidirectional, and this limits the choice of architectures that can be used during pre-training."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#@title Display\n",
    "display_sents = []\n",
    "\n",
    "for i, s in enumerate(sents):\n",
    "    line = '<font color=\"#CD5C5C\"><strong>' + s + '</strong></font>' if i in keys else s\n",
    "    display_sents.append(line)\n",
    "\n",
    "HTML(''.join(display_sents))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I dropped out of Reed College after the first 6 months, but then stayed around as a drop-in for another 18 months or so before I really quit.',\n",
       " 'It was the first computer with beautiful typography.',\n",
       " 'When I was young, there was an amazing publication called The Whole Earth Catalog, which was one of the bibles of my generation.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = []\n",
    "for i, s in enumerate(sents):\n",
    "    if i in keys:\n",
    "        summary.append(s) \n",
    "    else: pass\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
